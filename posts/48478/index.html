

<!DOCTYPE html>
<html lang="zh-CN" data-default-color-scheme=auto>



<head>
  <meta charset="UTF-8">
  <link rel="apple-touch-icon" sizes="76x76" href="/blog/img/favicon.png">
  <link rel="icon" href="/blog/img/favicon.png">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=5.0, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
  <meta name="theme-color" content="#2f4154">
  <meta name="author" content="å‘µå‘µå›">
  <meta name="keywords" content="">
  
    <meta name="description" content="æš‘æœŸè¯¾ç¨‹å¼ºåŒ–å­¦ä¹ ä¸äººå·¥æ™ºèƒ½ç¬”è®°">
<meta property="og:type" content="article">
<meta property="og:title" content="Reinforcement Learning and Artificial Intelligence">
<meta property="og:url" content="http://47.100.74.245/blog/posts/48478/index.html">
<meta property="og:site_name" content="è‹å–‚">
<meta property="og:description" content="æš‘æœŸè¯¾ç¨‹å¼ºåŒ–å­¦ä¹ ä¸äººå·¥æ™ºèƒ½ç¬”è®°">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="http://47.100.74.245/blog/post_img/81514130_p0_master1200.jpg">
<meta property="article:published_time" content="2022-07-29T23:13:58.535Z">
<meta property="article:modified_time" content="2022-07-29T23:13:58.535Z">
<meta property="article:author" content="å‘µå‘µå›">
<meta property="article:tag" content="RL">
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:image" content="http://47.100.74.245/blog/post_img/81514130_p0_master1200.jpg">
  
  
  <title>Reinforcement Learning and Artificial Intelligence - è‹å–‚</title>

  <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4/dist/css/bootstrap.min.css" />


  <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/github-markdown-css@4/github-markdown.min.css" />
  <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/hint.css@2/hint.min.css" />

  
    
    
      
      
        
          
          
          
        
        <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/prismjs@1/themes/prism-tomorrow.min.css" />
      
      
        <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/prismjs@1/plugins/line-numbers/prism-line-numbers.min.css" />
      
    
  

  
    <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3/dist/jquery.fancybox.min.css" />
  


<!-- ä¸»é¢˜ä¾èµ–çš„å›¾æ ‡åº“ï¼Œä¸è¦è‡ªè¡Œä¿®æ”¹ -->

<link rel="stylesheet" href="//at.alicdn.com/t/font_1749284_ba1fz6golrf.css">



<link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_lbnruvf0jn.css">


<link  rel="stylesheet" href="/blog/css/main.css" />

<!-- è‡ªå®šä¹‰æ ·å¼ä¿æŒåœ¨æœ€åº•éƒ¨ -->


  <script id="fluid-configs">
    var Fluid = window.Fluid || {};
    var CONFIG = {"hostname":"47.100.74.245","root":"/blog/","version":"1.8.14","typing":{"enable":true,"typeSpeed":70,"cursorChar":"_","loop":false},"anchorjs":{"enable":true,"element":"h1,h2,h3,h4,h5,h6","placement":"right","visible":"hover","icon":""},"progressbar":{"enable":true,"height_px":3,"color":"#29d","options":{"showSpinner":false,"trickleSpeed":100}},"copy_btn":true,"image_zoom":{"enable":true,"img_url_replace":["",""]},"toc":{"enable":true,"headingSelector":"h1,h2,h3,h4,h5,h6","collapseDepth":0},"lazyload":{"enable":true,"loading_img":"/img/loading.gif","onlypost":false,"offset_factor":2},"web_analytics":{"enable":true,"baidu":"5b545cafb70936459694733c37bcf02c","google":null,"gtag":null,"tencent":{"sid":null,"cid":null},"woyaola":null,"cnzz":null,"leancloud":{"app_id":null,"app_key":null,"server_url":null,"path":"window.location.pathname","ignore_local":false}},"search_path":"/blog/local-search.xml"};
  </script>
  <script  src="/blog/js/utils.js" ></script>
  <script  src="/blog/js/color-schema.js" ></script>
<meta name="generator" content="Hexo 5.4.0"></head>


<body>
  <header style="height: 70vh;">
    <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand" href="/blog/">
      <strong>è‹å–‚</strong>
    </a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/blog/">
                <i class="iconfont icon-home-fill"></i>
                é¦–é¡µ
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/blog/archives/">
                <i class="iconfont icon-archive-fill"></i>
                å½’æ¡£
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/blog/categories/">
                <i class="iconfont icon-category-fill"></i>
                åˆ†ç±»
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/blog/tags/">
                <i class="iconfont icon-tags-fill"></i>
                æ ‡ç­¾
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/blog/about/">
                <i class="iconfont icon-user-fill"></i>
                å…³äº
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/blog/links/">
                <i class="iconfont icon-link-fill"></i>
                å‹é“¾
              </a>
            </li>
          
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" target="_self" href="javascript:;" data-toggle="modal" data-target="#modalSearch" aria-label="Search">
              &nbsp;<i class="iconfont icon-search"></i>&nbsp;
            </a>
          </li>
        
        
          <li class="nav-item" id="color-toggle-btn">
            <a class="nav-link" target="_self" href="javascript:;" aria-label="Color Toggle">&nbsp;<i
                class="iconfont icon-dark" id="color-toggle-icon"></i>&nbsp;</a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

    <div class="banner" id="banner" parallax=true
         style="background: url('/blog/post_img/81514130_p0_master1200.jpg') no-repeat center center;
           background-size: cover;">
      <div class="full-bg-img">
        <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0.3)">
          <div class="page-header text-center fade-in-up">
            <span class="h2" id="subtitle" title="Reinforcement Learning and Artificial Intelligence">
              
            </span>

            
              <div class="mt-3">
  
  
    <span class="post-meta">
      <i class="iconfont icon-date-fill" aria-hidden="true"></i>
      <time datetime="2022-07-29 23:13" pubdate>
        2022å¹´7æœˆ29æ—¥ æ™šä¸Š
      </time>
    </span>
  
</div>

<div class="mt-1">
  
    <span class="post-meta mr-2">
      <i class="iconfont icon-chart"></i>
      16k å­—
    </span>
  

  
    <span class="post-meta mr-2">
      <i class="iconfont icon-clock-fill"></i>
      
      
      132 åˆ†é’Ÿ
    </span>
  

  
  
    
      <!-- ä¸è’œå­ç»Ÿè®¡æ–‡ç« PV -->
      <span id="busuanzi_container_page_pv" style="display: none">
        <i class="iconfont icon-eye" aria-hidden="true"></i>
        <span id="busuanzi_value_page_pv"></span> æ¬¡
      </span>
    
  
</div>

            
          </div>

          
        </div>
      </div>
    </div>
  </header>

  <main>
    
      

<div class="container-fluid nopadding-x">
  <div class="row nomargin-x">
    <div class="d-none d-lg-block col-lg-2"></div>
    <div class="col-lg-8 nopadding-x-md">
      <div class="container nopadding-x-md" id="board-ctn">
        <div class="py-5" id="board">
          <article class="post-content mx-auto">
            <!-- SEO header -->
            <h1 style="display: none">Reinforcement Learning and Artificial Intelligence</h1>
            
              <p class="note note-info">
                
                  æœ¬æ–‡æœ€åæ›´æ–°äºï¼šå‡ ç§’å‰
                
              </p>
            
            <div class="markdown-body">
              <h2 id="introduction">Introduction</h2>
<p>Reinforcement Learning (RL) is a <strong>scientific theory</strong> (or hypothesis) that seeks to provide a <strong>computational explanation</strong> to the widely <strong>observed phenomenon</strong> that some complex <strong>physical system</strong> can adapt to the <strong>physical environment</strong> around it.</p>
<ul>
<li>scientific theory: links an observation (i.e. the subject) to some other reproducible observations (i.e. the evidence) with logic.</li>
<li>computational explanation</li>
<li>observed phenomenon</li>
<li>physical system</li>
<li>physical environment</li>
</ul>
<p>The Rl regard the physical world as a Markov chain. Consider a physical system that interacts with a surrounding environment by exchanging mass/energy across the system boundary. The <strong>world (system + environment)</strong> changes over time, and is in a certain state <span class="math inline">\(\mathbf{s_t}\)</span> at each moment <span class="math inline">\(t\)</span>.</p>
<p>Different physical theories may formulate <span class="math inline">\(\mathbf{s_t}\)</span> into different mathematical objects (<span class="math inline">\(s\)</span> can be a vector, a tensor, a function, a function of functions, etc.). But in most physical theories, the time evolution of the state follows time-invariant (possibly stochastic) transition laws, such that <span class="math inline">\(\mathbf{s_t}\)</span> decouples the past from the future.</p>
<blockquote>
<p>Theorem (H. M. Sheffer, in Transactions of the American Mathematical Society, 1913): Every digital computer is functionally equivalent to an NAND network.</p>
</blockquote>
<h2 id="math-basics">Math Basics</h2>
<h3 id="probability-theory-basics">Probability Theory Basics</h3>
<blockquote>
<p>è¯¦è§æ¦‚ç‡è®ºç›¸å…³çš„æ–‡ç« ï¼Œè¿™é‡Œæ‘˜å½•ä¸€ä¸‹è¯¾ä¸Šçš„å¤§çº²</p>
</blockquote>
<h4 id="probability-space">Probability Space</h4>
<ul>
<li>Sample Space, a set of all â€œpossible worldsâ€ under concern, each with full certainty and definiteness.</li>
<li>Event Space, a set of all random events; each event may occur in a subset of the possible worlds.</li>
<li>Probability function, mapping that assigns a real number to each random event to indicate its â€œpropensity of occurrenceâ€.</li>
</ul>
<h4 id="joint-probability-union-probability-union-bound">Joint Probability, Union Probability, Union Bound</h4>
<p>Union Bound:</p>
<p><span class="math display">\[
\begin{array}{c}
  P[{A_1}or{A_1}or{\dotsb}{ {A_n} }]{\le}\sum_{i=1}^{n}P[A_i]
\end{array}
\]</span></p>
<h4 id="conditional-probability-independence">Conditional Probability, Independence</h4>
<p>The conditional probability has been in a new probability space, so much different with joint probability.And to point it, use <span class="math inline">\(P_B[A]\)</span> is better than <span class="math inline">\(P[A|B]\)</span>.</p>
<p>To change the probability space</p>
<p><span class="math display">\[
\begin{array}{c}
  P[AB]=P[A|B]P[B]=P[B|A]P[A]
\end{array}
\]</span></p>
<p>And if we want to add a probability of C</p>
<p><span class="math display">\[
\begin{array}{c}
  P[AB|C]=P[A|BC]P[BC], or this form\\
  P_C[AB]=P_C[AB]P_C[B].\\
\end{array}
\]</span></p>
<h4 id="random-variable">Random Variable</h4>
<p>If <span class="math inline">\(X\)</span> is continuous, we will (ab-)use ğ[ğ‘‹ = ğ‘¥] to refer (instead) to the probability density of <span class="math inline">\(X = x\)</span>.</p>
<p>If ğ‘‹ is continuous, we will (ab-)use Î£ğ‘¥ (instead of âˆ« dğ‘¥) to refer to the probabilistic integration</p>
<h4 id="probability-distribution">Probability Distribution</h4>
<p>A function ğ‘· is a probability distribution function if and only if (1) ğ‘ƒ ğ’™ â‰¥ ğŸ and (2) Ïƒğ’™ ğ‘ƒ(ğ’™) = ï¿½</p>
<h4 id="multivariate-variable-categorical-variable">Multivariate Variable, Categorical Variable</h4>
<ul>
<li>Multivariate variable (random vector), a vector of random variables.</li>
<li>Categorical variable, rand. var. whose values are â€œlabelsâ€ (rather than â€œnumbersâ€)</li>
<li>One-hot vectors, numerical representation for categorical variables</li>
</ul>
<h4 id="function-of-random-variable">Function of Random Variable</h4>
<p>For an ordinary, definite, and deterministic function, its output becomes a random variable if the input of the function is a random variable.</p>
<p>ğ ğ‘“ ğ‘‹ = ğ‘¦ = Ïƒ{ğ‘¥: ğ‘“ ğ‘¥ =ğ‘¦} ğ[ğ‘‹ = ğ‘¥]</p>
<h4 id="expectation-conditional-expectation-and-function-of-random-variables-expectation">Expectation, Conditional Expectation and Function of Random Variable's Expectation</h4>
<p>Expectation, also called expected value, or mean value, or simply the mean, is the probability-weighted average over all possible values of a random variable.</p>
<p>conditional expectation is conditioned on a random event, not on a random variable.</p>
<p>For a function, <span class="math inline">\(P[f(X)=y]=\sum_{\{x:f(x)=y\} }P[X=x]\)</span>, and <span class="math inline">\(E[f(X)]=\sum_{x}P[X=x]{\cdot}f(x)\)</span></p>
<p>typically used as <strong>distance unit</strong> to measure how far a particular value of ğ‘‹ deviates from the mean ğ„[ğ‘‹]</p>
<h4 id="variance-standard-deviation">Variance, Standard Deviation</h4>
<p>The variance of ğ‘‹ is the probability-weighted average of the squared distances between possible values of ğ‘‹ and its mean</p>
<p><span class="math display">\[
\begin{array}{c}
  Var[X]=E[(X-E[X])^2], and conveniently\\
  Var[X]=E[X^2]=(E[X])^2
\end{array}{c}
\]</span></p>
<p>Standard deviation <span class="math inline">\(\sigma(X)=\sqrt{Var[X]}\)</span></p>
<h4 id="covariance-and-correlation">Covariance and Correlation</h4>
<p>The covariance between two random variables ğ‘‹ and ğ‘Œ measures the tendency that the values of ğ‘‹ and ğ‘Œ jointly deviate in the same way from their respective mean values.</p>
<p>$$</p>
<p>$$</p>
<p>Pearson correlation coefficient normalizes the deviations by dividing the standard deviations, so that we always have 0 â‰¤ ğœŒ(ğ‘‹, ğ‘Œ) â‰¤ 1</p>
<p>For multivariate random variable ğ‘¿ = ğ‘‹1, ğ‘‹2, â€¦ ,ğ‘‹ğ‘› T, the covariance matrix of ğ‘¿consists of all the pairwise covariances between the elements in ğ‘¿</p>
<h4 id="entropy-and-cross-entropy">Entropy and Cross Entropy</h4>
<p>The entropy of a random variable ğ‘‹ characterizes the inherent uncertainty of ğ‘‹, or equivalently, the â€œexpected surpriseâ€ when observing a sample of ğ‘‹.</p>
<p>The uniform distribution is the maximum-entropy distribution among all probability distributions with the same support.</p>
<p>For two random variables ğ‘‹ and ğ‘Œ with the same support, the cross entropy of ğ’€relative to ğ‘¿ measures <strong>how ğ‘Œâ€™s distribution differs from ğ‘‹â€™s distribution</strong>.</p>
<p>Cross entropy (or more accurately, ğ‘¯ ğ’€ ğ‘¿ âˆ’ ğ‘¯(ğ‘¿), called the KL-divergence) is usually used as a measure of the <strong>distance between two distributions</strong></p>
<h3 id="parametric-models-in-statistics">Parametric Models in Statistics</h3>
<h4 id="gaussian-model">Gaussian Model</h4>
<p>Gaussian distribution is so widely observed that itâ€™s been called, the normal</p>
<p>å½“æ ·æœ¬æ•°æ® X æ˜¯ä¸€ç»´æ•°æ®ï¼ˆUnivariateï¼‰æ—¶ï¼Œé«˜æ–¯åˆ†å¸ƒéµä»ä¸‹æ–¹æ¦‚ç‡å¯†åº¦å‡½æ•°ï¼ˆProbability Density Functionï¼‰<sup>2</sup>ï¼š</p>
<p><span class="math display">\[
N(x;\mu,\sigma^2)={\frac{1}{\sigma \sqrt{2\pi} } }e^{ {-\frac{1}{2} }(\frac{x-\mu}{\sigma})^2}
\]</span></p>
<blockquote>
<p>A parametric model that well captures the probability distribution of not a single, but many random variables encountered in the real world.</p>
</blockquote>
<p><strong>Gaussian distribution</strong> has a single â€œpeakâ€ (called the mode of the distribution). For many random variables <span class="math inline">\(Y\)</span> in the real world, its marginal distribution <span class="math inline">\(P(y)\)</span> is <strong>multi-modal</strong>.</p>
<p>Sometimes such <span class="math inline">\(P(y)\)</span> can be decomposed into a mixture of unimodal distributions.</p>
<p><span class="math display">\[
P(y)=\sum_{x}P(x)P(y|x)
\]</span></p>
<p>where <span class="math inline">\(X\)</span> is another observable random variable.</p>
<p>we can fit the conditional distribution <span class="math inline">\(P(y|x)\)</span> , with a separate Gaussian function, for each <span class="math inline">\(x\)</span></p>
<p><span class="math display">\[
f(y;\mathbf{\theta})=\sum_{x}P(x)N(y;\mu_x,\sigma_x^2), \\
where {\quad}\mathbf{\theta}=({\mu_1},{\mu_2},\dotsb,{\mu_n},{\sigma_1},{\sigma_2},\dotsb,{\sigma_n})
\]</span></p>
<p><strong>Gaussian Mixture Model, GMM</strong> method seeks to estimate <span class="math inline">\(\mathbf{\theta}\)</span> for the mixture distribution <span class="math inline">\(f\)</span> without observing <span class="math inline">\(X\)</span>.</p>
<p>é«˜æ–¯æ··åˆæ¨¡å‹å¯ä»¥çœ‹ä½œæ˜¯ç”± K ä¸ªå•é«˜æ–¯æ¨¡å‹ç»„åˆè€Œæˆçš„æ¨¡å‹ï¼Œè¿™ K ä¸ªå­æ¨¡å‹æ˜¯æ··åˆæ¨¡å‹çš„éšå˜é‡ï¼ˆHidden variableï¼‰ã€‚ä¸€èˆ¬æ¥è¯´ï¼Œä¸€ä¸ªæ··åˆæ¨¡å‹å¯ä»¥ä½¿ç”¨ä»»ä½•æ¦‚ç‡åˆ†å¸ƒï¼Œè¿™é‡Œä½¿ç”¨é«˜æ–¯æ··åˆæ¨¡å‹æ˜¯å› ä¸ºé«˜æ–¯åˆ†å¸ƒå…·å¤‡å¾ˆå¥½çš„æ•°å­¦æ€§è´¨ä»¥åŠè‰¯å¥½çš„è®¡ç®—æ€§èƒ½<sup>2</sup>ã€‚</p>
<p>We can further factorize <span class="math inline">\(X\)</span> into a mixture distribution, depending on some <span class="math inline">\(Z\)</span>, and so on, eventually leading to a <strong>Probabilistic Graphical Model</strong> (called <strong>Bayesian Network</strong>)</p>
<h4 id="gaussian-linear-model1">Gaussian Linear Model<sup id="fnref:1" class="footnote-ref"><a href="#fn:1" rel="footnote"><span class="hint--top hint--rounded" aria-label="æœºå™¨å­¦ä¹ â€”â€”çº¿æ€§é«˜æ–¯æ¨¡å‹
">[1]</span></a></sup></h4>
<p>When <span class="math inline">\(X\)</span> has infinite support, we canâ€™t parameterize <span class="math inline">\(f\)</span> with a finite number of <span class="math inline">\(\mu x\)</span> and <span class="math inline">\(\sigma x\)</span>.</p>
<p>In this case, we can make <span class="math inline">\(\mu\)</span> (and <span class="math inline">\(\sigma\)</span>) a function of <span class="math inline">\(x\)</span>, and parameterize <span class="math inline">\(f\)</span> through parameterizing the functions <span class="math inline">\(\mu(x)\)</span> and <span class="math inline">\(\sigma(x)\)</span></p>
<p>Gaussian Linear Models (or Linear Gaussian Models) are parametric models that seek to fit the <strong>conditional probabilities</strong> <span class="math inline">\(P[Y=y|X=x]\)</span>, where both <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> are observablerandom variables, with a Gaussian function with linear mean:</p>
<p><span class="math display">\[
f(y|x;a,b,\sigma)=N(y;ax+b,\sigma)={\frac{1}{\sigma{\sqrt{2\pi} } } }e^{ {-\frac{1}{2} }{(\frac{y-(ax+b)}{\sigma})}^2}
\]</span></p>
<p>With separately learned distribution <span class="math inline">\(P(x)\)</span>, the Gaussian Linear function <span class="math inline">\(f(y|x;a,b,\sigma)\)</span>can model more complex marginal distribution of <span class="math inline">\(Y\)</span> (than a single Gaussian function can), <span class="math inline">\(P[Y=y]=\sigma_x{P(x)f(y|x;a,b,\sigma)}\)</span>.</p>
<p>Often, we just care about the conditional probability for its own sake (e.g. in policy learning), <span class="math inline">\(P[Y=y|X=x]=f(y|x;a,b,\sigma)\)</span>.</p>
<h4 id="maximum-likelihood-estimation-mle">Maximum Likelihood Estimation, MLE</h4>
<p>å¯¹äºå•é«˜æ–¯æ¨¡å‹ï¼Œæˆ‘ä»¬å¯ä»¥ç”¨æœ€å¤§ä¼¼ç„¶æ³•ä¼°ç®—å‚æ•° <span class="math inline">\(\mathbf{\theta}\)</span>çš„å€¼<sup id="fnref:2" class="footnote-ref"><a href="#fn:2" rel="footnote"><span class="hint--top hint--rounded" aria-label="é«˜æ–¯æ··åˆæ¨¡å‹ï¼ˆGMMï¼‰ - æˆ´æ–‡äº®çš„æ–‡ç«  - çŸ¥ä¹
">[2]</span></a></sup></p>
<p><span class="math display">\[
\prod^{n}_{i=1}{\mathbf{P_{\theta} } }[{Y_i}={y_i}|{X_i}={x_i}]=\prod^{n}_{i=1}f({x_i,y_i;\mathbf{\theta} })
\]</span></p>
<p>The MLE principle proposes to choose the parameter vector <span class="math inline">\(\mathbf{\theta}\)</span> that maximizes the function, which is equivalent to minimize the <strong>negative-log-likelihood (NLL) function</strong>:</p>
<p><span class="math display">\[
-\log{\prod^{n}_{i=1}f({x_i,y_i;\mathbf{\theta} })}=-{\sum_i}\log f({x_i,y_i;a,b,\sigma})={\frac{1}{2\sigma^2} }{({\sum_i}(a{x_i}+b-{y_i})^2)}+n\log{\sigma{\sqrt{2\pi} } }
\]</span></p>
<h4 id="gaussian-linear-model-with-multivariate">Gaussian Linear Model with Multivariate</h4>
<p>Multivariate Gaussian Linear Model is a parametric model that seeks to fit the conditional distribution <span class="math inline">\(Y=y|\mathbf{X}=\mathbf{x}\)</span>, where <span class="math inline">\(\mathbf{X}\)</span> is an observable <strong>multivariate random variable</strong>, such that</p>
<p><span class="math display">\[
f(y|\mathbf{x};\mathbf{w},\sigma)=N(y;{\mathbf{w}\cdot\mathbf{x} },\sigma)={\frac{1}{\sigma{\sqrt{2\pi} } } }e^{ {-\frac{1}{2} }{(\frac{y-{\mathbf{w}\cdot\mathbf{x} } }{\sigma})}^2}
\]</span></p>
<h4 id="gasussian-linear-regression-and-mean-squared-error-mse">Gasussian Linear Regression and Mean Squared Error, MSE</h4>
<p>The Gaussian linear function can be alternatively viewed as a parametric model for a â€œperturbed mappingâ€ from a vector variable ğ’™ to a scalar variable ğ‘¦, where the perturbation is a Gaussian noise <span class="math inline">\(\epsilon ~ N(0,\sigma^2)\)</span></p>
<p>Given observations and the parameter vector as the linear coefficients, can be equivalently chosen based on the <strong>Mean Squared Error (MSE) principle</strong>, without the explicit probabilistic interpretation</p>
<p><span class="math display">\[
{L_{MSE} }={\frac{1}{n} }\sum_i{(\mathbf{w\cdot x}-{y_i})^2}
\]</span></p>
<h4 id="logistic-regression">Logistic Regression</h4>
<p>æ·±åº¦å­¦ä¹ çš„å®è·µè¯´æ˜ï¼Œçº¿æ€§å›å½’æ€»æ˜¯å­˜åœ¨ä»–çš„å±€é™æ€§ã€‚</p>
<p>Generalized linear model in the form of</p>
<p><span class="math display">\[
g(\mathbb{}{x};\mathbb{w})=\phi(\mathbf{w}\cdot \mathbf{x}), {\quad}\phi(s)=\frac{1}{1+e^{-s} }
\]</span></p>
<p>or other function with the similar S-shape curve</p>
<h4 id="deep-logistic-networks">Deep Logistic Networks</h4>
<h2 id="elements-in-reinforcement-learning">Elements in Reinforcement Learning</h2>
<p><strong>RL is a Cross-disciplinary nature.</strong></p>
<figure>
<img src="https://tva1.sinaimg.cn/large/e6c9d24ely1h3ve5vqbuoj20xa0u0q5v.jpg" srcset="/blog/img/loading.gif" lazyload alt="image-20220705010806726" /><figcaption aria-hidden="true">image-20220705010806726</figcaption>
</figure>
<h3 id="origin-of-rl">Origin of RL</h3>
<p>Reinforcement: The observation that under some conditions, some stimulus has the effect that it can increase the likelihood of the action preceding it, with a reproducible pattern.</p>
<p>Behavioral psychology research not only gave birth to the name of RL, but more importantly, provides abundant experimental data for the RL theory to explain.</p>
<h3 id="the-policy">The Policy</h3>
<p>Policy is changing during learning.</p>
<p>When a system learns, the mapping rule between its inputs (=observations) and outputs (=actions) must be changing.</p>
<figure>
<img src="https://tva1.sinaimg.cn/large/e6c9d24ely1h3vef3efh3j20na0b03yy.jpg" srcset="/blog/img/loading.gif" lazyload alt="image-20220705011701586" /><figcaption aria-hidden="true">image-20220705011701586</figcaption>
</figure>
<p>The mapping rule is called <strong>a decision policy function</strong>, or just <strong>policy</strong> for short.</p>
<ul>
<li>Deterministic policy: <span class="math inline">\(\mathbf{a_t}=\pi(\mathbf{x_t})\)</span></li>
<li>Stochastic policy: <span class="math inline">\(P[{A_t}=\mathbf{a_t}|{X_t}=\mathbf{x_t}]=\pi(\mathbf{x_t},\mathbf{a_t})\)</span>,so that <span class="math inline">\({A_t}~\pi({x_t},\cdot)\)</span></li>
</ul>
<h4 id="parameterization">Parameterization</h4>
<p>For any system to learn anything, its policy <span class="math inline">\(\pi\)</span> must be able to change flexibly</p>
<p>With a parameter <span class="math inline">\(\theta\)</span>, we get</p>
<ul>
<li>Deterministic policy: <span class="math inline">\(\mathbf{a_t}=\pi(\mathbf{x_t},\theta)\)</span></li>
<li>Stochastic policy: <span class="math inline">\(P[{A_t}=\mathbf{a_t}|{X_t}=\mathbf{x_t}]=\pi(\mathbf{x_t},\mathbf{a_t},\theta)\)</span></li>
</ul>
<p>To change the model <span class="math inline">\(\pi\)</span>, we only need to change its parameter <span class="math inline">\(\theta\)</span>.</p>
<p>For flexible learning, we want the model to cover a large enough set of possible policy functions. For example, a linear model is impossible to learn effectively if the optimal policy is <span class="math inline">\(a=x^2\)</span>.</p>
<h4 id="trial-and-error">Trial and Error</h4>
<p>Trial and Error is family of optimization methods that can optimize an objective function <span class="math inline">\(J\)</span> without explicit knowledge (e.g. the closed form) about <span class="math inline">\(J\)</span>.</p>
<p>The trial-and-error process results in a trace of policies with improving performance</p>
<h3 id="related-modelspreview">Related models(preview)</h3>
<p>About parameterization:</p>
<ul>
<li>Regression models in statistics</li>
<li>Parameterization in biological neuronal networks</li>
<li>Artificial neural networks</li>
<li>From Genotype to Biological Fitness</li>
</ul>
<p>About trial and error:</p>
<ul>
<li>Evolution as a special form of trial-and-error learning</li>
<li>Evolutionary algorithms in AI</li>
<li>Policy Gradient Method, Stochastic Gradient Descent (SGD)</li>
<li>Bandit Algorithms, Upper Confidence Bound (UCB) Algorithm</li>
<li>Q-Learning</li>
<li>Monte-Carlo Tree Search</li>
<li>Correspondence in Cognitive Neuroscience</li>
<li>Deep Reinforcement Learning</li>
</ul>
<h2 id="biological-neural-nwtwork">Biological Neural Nwtwork</h2>
<p>Brain consists of two types of cells: glial cells and neurons.</p>
<figure>
<img src="https://tva1.sinaimg.cn/large/e6c9d24ely1h3x8m229o2j218e0u0gr7.jpg" srcset="/blog/img/loading.gif" lazyload alt="image-20220706152706244" /><figcaption aria-hidden="true">image-20220706152706244</figcaption>
</figure>
<figure>
<img src="https://tva1.sinaimg.cn/large/e6c9d24ely1h3x8nz6x74j21aa0fktbd.jpg" srcset="/blog/img/loading.gif" lazyload alt="image-20220706152905711" /><figcaption aria-hidden="true">image-20220706152905711</figcaption>
</figure>
<h3 id="integrate-and-fire-model">Integrate-and-fire Model</h3>
<p><strong>Action potential</strong> in pre-synaptic neuron induces <strong>response current</strong> in post-synaptic neuron.Resoonse current decays over time.</p>
<p><span class="math display">\[
{I_{response}({\Delta t})}={\frac{w_i}{\tau_s} }e^{-{\Delta t}/{\tau_s} }
\]</span></p>
<blockquote>
<p>Response currents from all synapses integrate through the dendrite of the post-synaptic neuron, accumulating potential imbalance in the membrane of the cell, until <strong>reaching a threshold</strong> at which point a post-synaptic action potential is released (which resets the membrane potential)</p>
</blockquote>
<p>Firing-rate model is a statistical model of biological neural networks, which assumes that functionality of a biological neural network mostly depends on <strong>frequency patterns of the action potentials</strong> flowing in the network, whose precise timing patterns do not matter.</p>
<p>The firing rate of a neuron is a <strong>function of time <span class="math inline">\(t\)</span></strong> which gives the <strong>frequency density of action potentials</strong> that the neuron would probabilistically release at each time point <span class="math inline">\(t\)</span>.</p>
<p><span class="math display">\[
{x(t)}=\lim_{ {\Delta t}\rightarrow 0}\mathbf{E}[\frac{ {spikes{\ }in}[t-{\Delta t},t]}{\Delta t}]
\]</span></p>
<p>Firing-rate <span class="math inline">\(x_i(\cdot)\)</span> of pre-synaptic neuron <span class="math inline">\(i\)</span> induces a response current <span class="math inline">\(I_i(\cdot)\)</span> at post synaptic neuron. Response currents from all synapses integrate into a total synaptic current <span class="math inline">\(I(\cdot)\)</span> which induces the firing-rate <span class="math inline">\(y(\cdot)\)</span> of the post-synaptic neuron.</p>
<p>Step by step,</p>
<ol type="1">
<li>Response current induced by a single action potential: <span class="math inline">\({I_{response}(\Delta t)}={\frac{w_i}{\tau_s} }e^{-{\Delta t}/{\tau_s} }\)</span></li>
<li>Response current induced by all spikes of synapse <span class="math inline">\(i\)</span>: <span class="math inline">\({I_i(t)}={\int_{-\infty}^{t} }{I_{response}(t-\tau){s_i(\tau)d\tau} }\)</span></li>
<li>Total synaptic current induced by all spikes of all synapses: <span class="math inline">\(I(t)=\sum_i{T_i(t)}\)</span></li>
</ol>
<p>Finally, firing rates <span class="math inline">\(\mathbf{x}\)</span> of all the pre-synaptic neurons collectively induce total synaptic current <span class="math inline">\(I\)</span> at the post-synaptic neuron:</p>
<p><span class="math display">\[
{\tau_s}{\frac{\mathrm{d}I}{\mathrm{d}t} }=-I\,+\,\mathbf{w}\cdot\mathbf{x}
\]</span></p>
<p>Total synaptic current <span class="math inline">\(I\)</span> determines the firing rate <span class="math inline">\(y\)</span> of the post-synaptic neuron</p>
<p><span class="math display">\[
{\tau_r}{\frac{\mathrm{d}y}{\mathrm{d}t} }=-y+\phi(I)
\]</span></p>
<p>where <span class="math inline">\(\phi(\cdot)\)</span> is called the <strong>activation function</strong> of the (post-synaptic) neuron.</p>
<h3 id="activity-independent-synaptic-plasticity-and-hebbian-rule">Activity-independent Synaptic Plasticity and Hebbian Rule</h3>
<p><strong>Plasticity</strong> is the ability of a solid material to undergo permanent deformation, a persistent change of shape in response to applied forces.</p>
<p>Changes of a synapseâ€™s strength <span class="math inline">\(w\)</span> that persist for tens of minutes or longer are generally called long-term potentiation (LTP) and long-term depression (LTD). Activity-dependent long-term synaptic plasticity is widely believed to be the biological foundation underlying the phenomenon of learning and memory.</p>
<p>The <strong>Hebbian theory</strong> is the best-known model for activity-dependent long-term synaptic plasticity. The <strong>Hebbian rule</strong> states that synapses change in proportion to the covariance between activities of the pre- and post-synaptic neurons.</p>
<p>èµ«å¸ƒç†è®ºï¼ˆè‹±èªï¼šHebbian theoryï¼‰æ˜¯ä¸€ä¸ªç¥ç»ç§‘å­¦ç†è®ºï¼Œè§£é‡Šäº†åœ¨å­¦ä¹ çš„è¿‡ç¨‹ä¸­è„‘ä¸­çš„ç¥ç»å…ƒæ‰€å‘ç”Ÿçš„å˜åŒ–ã€‚èµ«å¸ƒç†è®ºæè¿°äº†çªè§¦å¯å¡‘æ€§çš„åŸºæœ¬åŸç†ï¼Œå³çªè§¦å‰ç¥ç»å…ƒå‘çªè§¦åç¥ç»å…ƒçš„æŒç»­é‡å¤çš„åˆºæ¿€ï¼Œå¯ä»¥å¯¼è‡´çªè§¦ä¼ é€’æ•ˆèƒ½çš„å¢åŠ ã€‚è¿™ä¸€ç†è®ºç”±å”çº³å¾·Â·èµ«å¸ƒäº1949å¹´æå‡ºï¼Œåˆè¢«ç§°ä¸ºèµ«å¸ƒå®šå¾‹ï¼ˆHebb's ruleï¼‰ã€èµ«å¸ƒå‡è¯´ï¼ˆHebb's postulateï¼‰ã€ç»†èƒç»“é›†ç†è®ºï¼ˆcell assembly theoryï¼‰ç­‰<sup id="fnref:3" class="footnote-ref"><a href="#fn:3" rel="footnote"><span class="hint--top hint--rounded" aria-label="èµ«å¸ƒç†è®º - ç»´åŸºç™¾ç§‘
">[3]</span></a></sup>ã€‚</p>
<p>â€œå½“ç¥ç»å…ƒ A çš„ä¸€ä¸ªè½´çªå’Œç¥ç»å…ƒ B å¾ˆè¿‘ï¼Œè¶³ä»¥ å¯¹å®ƒäº§ç”Ÿå½±å“ï¼Œå¹¶ä¸”æŒç»­åœ°ã€é‡å¤åœ°å‚ä¸äº†å¯¹ç¥ç»å…ƒ B çš„å…´å¥‹ï¼Œé‚£ä¹ˆåœ¨è¿™ä¸¤ä¸ªç¥ ç»å…ƒæˆ–å…¶ä¸­ä¹‹ä¸€ä¼šå‘ç”ŸæŸç§ç”Ÿé•¿è¿‡ç¨‹æˆ–æ–°é™ˆä»£è°¢å˜åŒ–ï¼Œä»¥è‡´ç¥ç»å…ƒ A ä½œä¸ºèƒ½ä½¿ ç¥ç»å…ƒBå…´å¥‹çš„ç»†èƒä¹‹ä¸€ï¼Œå®ƒçš„æ•ˆèƒ½åŠ å¼ºäº†ï¼â€è¿™ä¸ªæœºåˆ¶ç§°ä¸ºèµ«å¸ƒç†è®ºï¼ˆHebbian Theoryï¼‰æˆ–èµ«å¸ƒè§„åˆ™ï¼ˆHebbian Ruleï¼Œæˆ– Hebbâ€™s Ruleï¼‰ï¼å¦‚æœä¸¤ä¸ªç¥ç»å…ƒæ€»æ˜¯ç›¸ å…³è”åœ°å—åˆ°åˆºæ¿€ï¼Œå®ƒä»¬ä¹‹é—´çš„çªè§¦å¼ºåº¦å¢åŠ ï¼è¿™æ ·çš„å­¦ä¹ æ–¹æ³•è¢«ç§°ä¸ºèµ«å¸ƒå‹å­¦ä¹  ï¼ˆHebbian learningï¼‰ï¼Hebbè®¤ä¸ºäººè„‘æœ‰ä¸¤ç§è®°å¿†ï¼šé•¿æœŸè®°å¿†å’ŒçŸ­æœŸè®°å¿†ï¼çŸ­æœŸè®° å¿†æŒç»­æ—¶é—´ä¸è¶…è¿‡ä¸€åˆ†é’Ÿï¼å¦‚æœä¸€ä¸ªç»éªŒé‡å¤è¶³å¤Ÿçš„æ¬¡æ•°ï¼Œæ­¤ç»éªŒå°±å¯å‚¨å­˜åœ¨é•¿ æœŸè®°å¿†ä¸­ï¼çŸ­æœŸè®°å¿†è½¬åŒ–ä¸ºé•¿æœŸè®°å¿†çš„è¿‡ç¨‹å°±ç§°ä¸ºå‡å›ºä½œç”¨ï¼äººè„‘ä¸­çš„æµ·é©¬åŒºä¸º å¤§è„‘ç»“æ„å‡å›ºä½œç”¨çš„æ ¸å¿ƒåŒºåŸŸ<sup id="fnref:4" class="footnote-ref"><a href="#fn:4" rel="footnote"><span class="hint--top hint--rounded" aria-label="æœºå™¨å­¦ä¹ ç®€ä»‹
">[4]</span></a></sup></p>
<ul>
<li>Let real number <span class="math inline">\(w\)</span> denote the <strong>strength of an excitatory synapse</strong>, <span class="math inline">\(x(t)\)</span> and <span class="math inline">\(y(t)\)</span> the pre- and post-synaptic firing rates at time <span class="math inline">\(t\)</span>,</li>
</ul>
<p><span class="math display">\[
{\tau_w}{\frac{\mathrm{d}w}{\mathrm{d}t} }=x(t){\,}y(t)
\]</span></p>
<ul>
<li>Let <strong>random variable</strong> <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> be the pre- and post-synaptic firing rates at a random time <span class="math inline">\(\tau\)</span> in a time window <span class="math inline">\([t-{\Delta t},t]\)</span>,</li>
</ul>
<p><span class="math display">\[
{\tau_w}{\frac{\mathrm{d}w}{\mathrm{d}t} }=\mathbf{E}[XY]-{\mathbf{E}[X]}{\mathbf{E}[Y]}
\]</span></p>
<h2 id="artificial-neural-networks-ann">Artificial Neural Networks, ANN</h2>
<blockquote>
<p>ANNåœ¨ç»Ÿè®¡é¢†åŸŸç”±äºéš¾ä»¥è¯æ˜ï¼Œè¿‘å‡ å¹´è™½ç„¶åœ¨åŠ¨åŠ›ç³»ç»Ÿã€æŠ½è±¡ä»£æ•°çš„æ–¹å‘ä¸Šæœ‰ç ”ç©¶ï¼Œä½†å¯è§£é‡Šæ€§è¿˜æ˜¯æ¯”è¾ƒå·®ï¼›ç”Ÿç‰©ç§‘å­¦æ–¹é¢ï¼Œè¿‡äºå¤æ‚çš„è„‘ç¥ç»ç³»ç»Ÿä»ç„¶éš¾ä»¥æ¨¡ä»¿ï¼Œä¸è¿‡è¯è¯´å›æ¥ï¼Œå…¨è„‘æ¨¡æ‹Ÿä¹Ÿç¡®å®æ˜¯ä¸€ä¸ªç ”ç©¶æ–¹å‘ï¼›æœ€åï¼ŒAIé¢†åŸŸæ›¾åœ¨æ—©æœŸè¢«æå‡ºï¼Œä½†ç”±äºè¿‡äºåºå¤§è¢«æç½®äº†æ•°åå¹´</p>
</blockquote>
<p>Parameterization in AI:</p>
<ul>
<li>Neural-network models</li>
<li>Tabular models</li>
<li>Non-differentiable models</li>
</ul>
<h3 id="multi-layer-perceptron-mlp">Multi-Layer Perceptron, MLP</h3>
<figure>
<img src="https://tva1.sinaimg.cn/large/e6c9d24ely1h3ycb4jbvej20si0jcn08.jpg" srcset="/blog/img/loading.gif" lazyload alt="image-20220707142039567" /><figcaption aria-hidden="true">image-20220707142039567</figcaption>
</figure>
<p>Each hidden-layer and ouput-layer node <span class="math inline">\(i\)</span> repoesents a sub-mode <span class="math inline">\(g(\mathbf{x};\mathbf{w_i},b_i)=\phi({\mathbf{w_i}\cdot{\mathbf{x} }+{b_i} })\)</span>. If define <span class="math inline">\(\mathbf{\bar{x} }=(\mathbf{x},1)^T,{\;}\bar{\mathbf{w_i} }=(\mathbf{w_i},{b_i})\)</span></p>
<h3 id="activitation-functions">Activitation Functions</h3>
<ul>
<li><p>Sigmoid, it can seperate when the <strong>input is too large</strong>: <span class="math display">\[
\sigma(x)=\frac{1}{1+e^{-x} }
\]</span></p></li>
<li><p>tanh: <span class="math inline">\(\tanh(x)\)</span></p></li>
<li><p>ReLU: <span class="math inline">\(max(0,x)\)</span></p></li>
<li><p>Leaky</p></li>
<li><p>ReLU</p></li>
<li><p>Maxout</p></li>
<li><p>ELU</p></li>
</ul>
<p>ä¸€ä¸ªMLPæ¨¡å‹çš„éœ€è¦çš„å‚æ•°æ˜¯éå¸¸å¤šçš„ï¼Œä»¥ä¸€ä¸ªè¾“å…¥<span class="math inline">\(\mathbb{R}^5\)</span>ï¼Œæœ‰ä¸¤ä¸ª<span class="math inline">\(\mathbb{R}^7\)</span>éšè—å±‚å¹¶è¾“å‡º<span class="math inline">\(\mathbb{R}^4\)</span>çš„ç½‘ç»œæ¥è®²ï¼Œä»–éœ€è¦çš„å‚æ•°æ˜¯</p>
<p><span class="math display">\[
n=[(N_{input}+1)\cdot{N_{next} }]+[(N_{hidden1}+1)\cdot{N_{next} }]+[(N_{hidden2}+1)\cdot{N_{output} }]=170
\]</span></p>
<p>A <strong>decision policy</strong> determines the probability that an â€œintelligentâ€ system would output a particular â€œactionâ€ in a time step conditioned on aparticular â€œstateâ€ of the system.</p>
<p>A policy function ğœ‹ is a conditional probability distribution. As a probability distribution, any policy function has to satisfy the following constraints</p>
<figure>
<img src="https://tva1.sinaimg.cn/large/e6c9d24ely1h3ycvp1fuaj20wu0fuad9.jpg" srcset="/blog/img/loading.gif" lazyload alt="image-20220707144028629" /><figcaption aria-hidden="true">image-20220707144028629</figcaption>
</figure>
<p>For a discrete output, define <strong>softmax function</strong> and add it to the output layer</p>
<p><span class="math display">\[
\sigma:\mathbb{R}^K{\rightarrow}[0,1]^K,{\;}where{\;}\sigma_i(z)={\frac{e^{z_i} }{\sum_{j=1}^K}{e^{z_j} } },{\,} for{\,} i=1,\dotsb,K
\]</span></p>
<blockquote>
<p>ç”±äºæŒ‡æ•°çš„å¢é•¿é€Ÿç‡å¾ˆå¤§ï¼Œè¿™ä¸ªå‡½æ•°å¯ä»¥â€œæŸ”è½¯â€çš„æ”¾å¤§è¾“å‡ºä¹‹é—´çš„å·®å¼‚ï¼Œå¹¶å…±åŒæˆä¸ºä¸€ä¸ªæ¦‚ç‡åˆ†å¸ƒå‡½æ•°ã€‚</br> Softmax functionæ˜¯ä¸ºäº†å°†è¾“å‡ºè½¬æ¢ä¸ºä¸€ä¸ªæ¡ä»¶æ¦‚ç‡ï¼Œè€Œä¸æ˜¯è·å¾—ä¸€ä¸ªæœ€å¤§å€¼ã€‚</p>
</blockquote>
<p>Then <span class="math inline">\(\pi(\mathbf{s},\mathbf{a};\mathbf{\theta})=\sigma(f_{MLP}(\mathbf{s};\mathbf{\theta}))\cdot\mathbf{a}\)</span></p>
<p>å…¶ä¸­<span class="math inline">\(\mathbf{a}\)</span>æ˜¯ä¸€ç»„one-hot vectorã€‚</p>
<figure>
<img src="https://tva1.sinaimg.cn/large/e6c9d24ely1h3yd81y6lyj21400fgq6i.jpg" srcset="/blog/img/loading.gif" lazyload alt="image-20220707144606874" /><figcaption aria-hidden="true">image-20220707144606874</figcaption>
</figure>
<h3 id="example-locomotion-control">Example: Locomotion Control</h3>
<h3 id="domain-specific-nn-architecture">Domain-specific NN architecture</h3>
<h4 id="convolutional-network">Convolutional Network</h4>
<figure>
<img src="https://tva1.sinaimg.cn/large/e6c9d24ely1h3yec7ew8rj214u0q6tc2.jpg" srcset="/blog/img/loading.gif" lazyload alt="image-20220707153056204" /><figcaption aria-hidden="true">image-20220707153056204</figcaption>
</figure>
<h4 id="transformer-network">Transformer Network</h4>
<figure>
<img src="https://tva1.sinaimg.cn/large/e6c9d24ely1h3yem057wej21z60magpd.jpg" srcset="/blog/img/loading.gif" lazyload alt="image-20220707154021201" /><figcaption aria-hidden="true">image-20220707154021201</figcaption>
</figure>
<h4 id="graph-network">Graph Network</h4>
<figure>
<img src="https://tva1.sinaimg.cn/large/e6c9d24ely1h3yep7une0j210g0jmwfq.jpg" srcset="/blog/img/loading.gif" lazyload alt="image-20220707154326848" /><figcaption aria-hidden="true">image-20220707154326848</figcaption>
</figure>
<h2 id="tabular-model-and-non-differential-model">Tabular Model and Non-differential Model</h2>
<p>A tabular model is a parametric model that covers the entire policy space.</p>
<h2 id="biological-evolution">Biological Evolution</h2>
<h2 id="homeworkds">HomeWorkds</h2>
<h3 id="homework-1.a">homework-1.a</h3>
<h2 id="references">References</h2>
<section class="footnotes">
<div class="footnote-list">
<ol>
<li>
<span id="fn:1" class="footnote-text"><span><a target="_blank" rel="noopener" href="https://www.cnblogs.com/young978/p/15813842.html">æœºå™¨å­¦ä¹ â€”â€”çº¿æ€§é«˜æ–¯æ¨¡å‹</a> <a href="#fnref:1" rev="footnote" class="footnote-backref"> â†©ï¸</a></span></span>
</li>
<li>
<span id="fn:2" class="footnote-text"><span><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/30483076">é«˜æ–¯æ··åˆæ¨¡å‹ï¼ˆGMMï¼‰ - æˆ´æ–‡äº®çš„æ–‡ç«  - çŸ¥ä¹</a> <a href="#fnref:2" rev="footnote" class="footnote-backref"> â†©ï¸</a></span></span>
</li>
<li>
<span id="fn:3" class="footnote-text"><span><a target="_blank" rel="noopener" href="https://zh.m.wikipedia.org/zh/èµ«å¸ƒç†è®º">èµ«å¸ƒç†è®º - ç»´åŸºç™¾ç§‘</a> <a href="#fnref:3" rev="footnote" class="footnote-backref"> â†©ï¸</a></span></span>
</li>
<li>
<span id="fn:4" class="footnote-text"><span><a target="_blank" rel="noopener" href="https://blog.csdn.net/qq_40808154/article/details/115407544">æœºå™¨å­¦ä¹ ç®€ä»‹</a> <a href="#fnref:4" rev="footnote" class="footnote-backref"> â†©ï¸</a></span></span>
</li>
</ol>
</div>
</section>

            </div>
            <hr>
            <div>
              <div class="post-metas mb-3">
                
                  <div class="post-meta mr-3">
                    <i class="iconfont icon-category"></i>
                    
                      <a class="hover-with-bg" href="/blog/categories/AI/">AI</a>
                    
                  </div>
                
                
                  <div class="post-meta">
                    <i class="iconfont icon-tags"></i>
                    
                      <a class="hover-with-bg" href="/blog/tags/RL/">RL</a>
                    
                  </div>
                
              </div>
              
                <p class="note note-warning">
                  
                    æœ¬åšå®¢æ‰€æœ‰æ–‡ç« é™¤ç‰¹åˆ«å£°æ˜å¤–ï¼Œå‡é‡‡ç”¨ <a target="_blank" href="https://creativecommons.org/licenses/by-sa/4.0/deed.zh" rel="nofollow noopener noopener">CC BY-SA 4.0 åè®®</a> ï¼Œè½¬è½½è¯·æ³¨æ˜å‡ºå¤„ï¼
                  
                </p>
              
              
                <div class="post-prevnext">
                  <article class="post-prev col-6">
                    
                    
                      <a href="/blog/posts/21062/">
                        <i class="iconfont icon-arrowleft"></i>
                        <span class="hidden-mobile">Pythonå…¥é—¨</span>
                        <span class="visible-mobile">ä¸Šä¸€ç¯‡</span>
                      </a>
                    
                  </article>
                  <article class="post-next col-6">
                    
                    
                      <a href="/blog/posts/63900/">
                        <span class="hidden-mobile">Thinking in Java ç¬”è®°</span>
                        <span class="visible-mobile">ä¸‹ä¸€ç¯‡</span>
                        <i class="iconfont icon-arrowright"></i>
                      </a>
                    
                  </article>
                </div>
              
            </div>

            
              <!-- Comments -->
              <article class="comments" id="comments" lazyload>
                
                  
                
                
  <div id="valine"></div>
  <script type="text/javascript">
    Fluid.utils.loadComments('#valine', function() {
      Fluid.utils.createScript('https://cdn.jsdelivr.net/npm/valine@1/dist/Valine.min.js', function() {
        var options = Object.assign(
          {"appId":"8fmElDB8yTQ6Cpsn0mbNbdxd-gzGzoHsz","appKey":"WIsNNq3yinfKJBndF0qqO31p","path":"window.location.pathname","placeholder":null,"avatar":"retro","meta":["nick","mail","link"],"requiredFields":[],"pageSize":10,"lang":"zh-CN","highlight":true,"recordIP":false,"serverURLs":"","emojiCDN":"//i0.hdslb.com/bfs/emote/","emojiMaps":{"tv_doge":"6ea59c827c414b4a2955fe79e0f6fd3dcd515e24.png","tv_äº²äº²":"a8111ad55953ef5e3be3327ef94eb4a39d535d06.png","tv_å·ç¬‘":"bb690d4107620f1c15cff29509db529a73aee261.png","tv_å†è§":"180129b8ea851044ce71caf55cc8ce44bd4a4fc8.png","tv_å†·æ¼ ":"b9cbc755c2b3ee43be07ca13de84e5b699a3f101.png","tv_å‘æ€’":"34ba3cd204d5b05fec70ce08fa9fa0dd612409ff.png","tv_å‘è´¢":"34db290afd2963723c6eb3c4560667db7253a21a.png","tv_å¯çˆ±":"9e55fd9b500ac4b96613539f1ce2f9499e314ed9.png","tv_åè¡€":"09dd16a7aa59b77baa1155d47484409624470c77.png","tv_å‘†":"fe1179ebaa191569b0d31cecafe7a2cd1c951c9d.png","tv_å‘•å":"9f996894a39e282ccf5e66856af49483f81870f3.png","tv_å›°":"241ee304e44c0af029adceb294399391e4737ef2.png","tv_åç¬‘":"1f0b87f731a671079842116e0991c91c2c88645a.png","tv_å¤§ä½¬":"093c1e2c490161aca397afc45573c877cdead616.png","tv_å¤§å“­":"23269aeb35f99daee28dda129676f6e9ea87934f.png","tv_å§”å±ˆ":"d04dba7b5465779e9755d2ab6f0a897b9b33bb77.png","tv_å®³ç¾":"a37683fb5642fa3ddfc7f4e5525fd13e42a2bdb1.png","tv_å°´å°¬":"7cfa62dafc59798a3d3fb262d421eeeff166cfa4.png","tv_å¾®ç¬‘":"70dc5c7b56f93eb61bddba11e28fb1d18fddcd4c.png","tv_æ€è€ƒ":"90cf159733e558137ed20aa04d09964436f618a1.png","tv_æƒŠå“":"0d15c7e2ee58e935adc6a7193ee042388adc22af.png"},"enableQQ":true},
          {
            el: "#valine",
            path: window.location.pathname
          }
        )
        new Valine(options);
        Fluid.utils.waitElementVisible('#valine .vcontent', () => {
          Fluid.plugins.initFancyBox('#valine .vcontent img:not(.vemoji)');
        })
      });
    });
  </script>
  <noscript>Please enable JavaScript to view the comments</noscript>


              </article>
            
          </article>
        </div>
      </div>
    </div>
    
      <div class="d-none d-lg-block col-lg-2 toc-container" id="toc-ctn">
        <div id="toc">
  <p class="toc-header"><i class="iconfont icon-list"></i>&nbsp;ç›®å½•</p>
  <div class="toc-body" id="toc-body"></div>
</div>

      </div>
    
  </div>
</div>

<!-- Custom -->


    

    
      <a id="scroll-top-button" aria-label="TOP" href="#" role="button">
        <i class="iconfont icon-arrowup" aria-hidden="true"></i>
      </a>
    

    
      <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">æœç´¢</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v"
                 for="local-search-input">å…³é”®è¯</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>
    

    
  </main>

  <footer class="text-center mt-5 py-3">
  <div class="footer-content">
     <a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span>Hexo</span></a> <i class="iconfont icon-love"></i> <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener"><span>Fluid</span></a> <div style="font-size: 0.85rem"> <span id="timeDate">è½½å…¥å¤©æ•°...</span> <span id="times">è½½å…¥æ—¶åˆ†ç§’...</span> <script src="/js/duration.js"></script> </div>
  </div>
  
  <div class="statistics">
    
    

    
      
        <!-- ä¸è’œå­ç»Ÿè®¡PV -->
        <span id="busuanzi_container_site_pv" style="display: none">
            æ€»è®¿é—®é‡ 
            <span id="busuanzi_value_site_pv"></span>
             æ¬¡
          </span>
      
      
        <!-- ä¸è’œå­ç»Ÿè®¡UV -->
        <span id="busuanzi_container_site_uv" style="display: none">
            æ€»è®¿å®¢æ•° 
            <span id="busuanzi_value_site_uv"></span>
             äºº
          </span>
      
    
  </div>


  

  
</footer>


  <!-- SCRIPTS -->
  
  <script  src="https://cdn.jsdelivr.net/npm/nprogress@0/nprogress.min.js" ></script>
  <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/nprogress@0/nprogress.min.css" />

  <script>
    NProgress.configure({"showSpinner":false,"trickleSpeed":100})
    NProgress.start()
    window.addEventListener('load', function() {
      NProgress.done();
    })
  </script>


<script  src="https://cdn.jsdelivr.net/npm/jquery@3/dist/jquery.min.js" ></script>
<script  src="https://cdn.jsdelivr.net/npm/bootstrap@4/dist/js/bootstrap.min.js" ></script>
<script  src="/blog/js/events.js" ></script>
<script  src="/blog/js/plugins.js" ></script>

<!-- Plugins -->


  <script  src="/blog/js/local-search.js" ></script>



  
    <script  src="/blog/js/img-lazyload.js" ></script>
  



  
    
      <script  src="https://cdn.jsdelivr.net/npm/prismjs@1/components/prism-core.min.js" ></script>
      <script  src="https://cdn.jsdelivr.net/npm/prismjs@1/plugins/autoloader/prism-autoloader.min.js" ></script>
      
        <script  src="https://cdn.jsdelivr.net/npm/prismjs@1/plugins/line-numbers/prism-line-numbers.min.js" ></script>
      
    
  



  
    <script  src="https://cdn.jsdelivr.net/npm/tocbot@4/dist/tocbot.min.js" ></script>
  
  
    <script  src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3/dist/jquery.fancybox.min.js" ></script>
  
  
    <script  src="https://cdn.jsdelivr.net/npm/anchor-js@4/anchor.min.js" ></script>
  
  
    <script defer src="https://cdn.jsdelivr.net/npm/clipboard@2/dist/clipboard.min.js" ></script>
  



  <script defer src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" ></script>




  <script  src="https://cdn.jsdelivr.net/npm/typed.js@2/lib/typed.min.js" ></script>
  <script>
    (function (window, document) {
      var typing = Fluid.plugins.typing;
      var title = document.getElementById('subtitle').title;
      
        typing(title);
      
    })(window, document);
  </script>





  

  
    <!-- MathJax -->
    <script>
      MathJax = {
        tex: {
          inlineMath: [['$', '$'], ['\\(', '\\)']]
        },
        loader: {
          load: ['ui/lazy']
        },
        options: {
          renderActions: {
            findScript: [10, doc => {
              document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
                const display = !!node.type.match(/; *mode=display/);
                const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
                const text = document.createTextNode('');
                node.parentNode.replaceChild(text, node);
                math.start = { node: text, delim: '', n: 0 };
                math.end = { node: text, delim: '', n: 0 };
                doc.math.push(math);
              });
            }, '', false],
            insertedScript: [200, () => {
              document.querySelectorAll('mjx-container').forEach(node => {
                let target = node.parentNode;
                if (target.nodeName.toLowerCase() === 'li') {
                  target.parentNode.classList.add('has-jax');
                }
              });
            }, '', false]
          }
        }
      };
    </script>

    <script async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-svg.js" ></script>

  








  
    <!-- Baidu Analytics -->
    <script defer>
      var _hmt = _hmt || [];
      (function () {
        var hm = document.createElement("script");
        hm.src = "https://hm.baidu.com/hm.js?5b545cafb70936459694733c37bcf02c";
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(hm, s);
      })();
    </script>
  

  

  

  

  

  





<!-- ä¸»é¢˜çš„å¯åŠ¨é¡¹ ä¿æŒåœ¨æœ€åº•éƒ¨ -->
<script  src="/blog/js/boot.js" ></script>


<!-- hexo injector body_end start -->
  <script data-pjax src="https://cdn.jsdelivr.net/gh/Zfour/hexo-github-calendar@1.21/hexo_githubcalendar.js"></script>
  <script data-pjax>
        function GithubCalendarConfig(){
            var git_githubapiurl ="https://python-github-calendar-api.vercel.app/api?zghehejun233";
            var git_color =['#ebedf0', '#f1f8ff', '#dbedff', '#c8e1ff', '#79b8ff', '#2188ff', '#0366d6', '#005cc5', '#044289', '#032f62', '#05264c'];
            var git_user ="zghehejun233";
            var parent_div_git = document.getElementById('recent-posts');
            var git_div_html = '<div id="github-calendar" style="width:100%;height:auto;padding:10px;margin-bottom:20px"><div id="github_loading" style="width:10%;height:100%;margin:0 auto;display: block"><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"  viewBox="0 0 50 50" style="enable-background:new 0 0 50 50" xml:space="preserve"><path fill="#d0d0d0" d="M25.251,6.461c-10.318,0-18.683,8.365-18.683,18.683h4.068c0-8.071,6.543-14.615,14.615-14.615V6.461z" transform="rotate(275.098 25 25)"><animateTransform attributeType="xml" attributeName="transform" type="rotate" from="0 25 25" to="360 25 25" dur="0.6s" repeatCount="indefinite"></animateTransform></path></svg></div><div id="github_container"></div></div>';
            if(parent_div_git && location.pathname =='/blog/about'){
                console.log('å·²æŒ‚è½½github calendar')
                // parent_div_git.innerHTML=git_div_html+parent_div_git.innerHTML // æ— æŠ¥é”™ï¼Œä½†ä¸å½±å“ä½¿ç”¨(æ”¯æŒpjaxè·³è½¬)
                parent_div_git.insertAdjacentHTML("afterbegin",git_div_html) // æœ‰æŠ¥é”™ï¼Œä½†ä¸å½±å“ä½¿ç”¨(æ”¯æŒpjaxè·³è½¬)
            };
            GithubCalendar(git_githubapiurl,git_color,git_user)
        }
        if(document.getElementById('recent-posts')){
            GithubCalendarConfig()
        }
    </script>
    <style>#github_container{min-height:200px}@media screen and (max-width:650px) {#github_container{background-image:;min-height:0px}}</style>
    <style>#github_container > .position-relative > .border{border:0!important}#github-calendar{position: relative;margin-top: -2rem;background-color: var(--board-bg-color);transition: background-color 0.2s ease-in-out;border-radius: 0.5rem;z-index: 3;-webkit-box-shadow: 0 12px 15px 0 rgb(0 0 0 / 24%), 0 17px 50px 0 rgb(0 0 0 / 19%);box-shadow: 0 12px 15px 0 rgb(0 0 0 / 24%), 0 17px 50px 0 rgb(0 0 0 / 19%);}</style><!-- hexo injector body_end end --></body>
</html>
